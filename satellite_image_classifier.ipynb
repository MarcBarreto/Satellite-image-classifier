{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "z-io_WItf4kX",
        "nHFP2Wekf-F-",
        "yXodnYTPp0Td",
        "dRk-9lijtgp4",
        "kBwTJrSa2iEL",
        "JSrH9ZIg4xrY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8STTv21TwiNi"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch\n",
        "import shutil\n",
        "import random\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import seaborn as sns\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "from torchvision.datasets import ImageFolder\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU Memory Reset\n",
        "from numba import cuda\n",
        "device = cuda.get_current_device()\n",
        "device.reset()"
      ],
      "metadata": {
        "id": "GGzxPNkTyF4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Loading Data**"
      ],
      "metadata": {
        "id": "z-io_WItf4kX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2mKNCAL0O-u",
        "outputId": "929141da-ba88-429a-ac72-9911eda0b4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove folders from dataset\n",
        "try:\n",
        "  shutil.rmtree('EuroSAT_RGB')\n",
        "  shutil.rmtree('__MACOSX')\n",
        "  shutil.rmtree('imagens_treino')\n",
        "  shutil.rmtree('imagens_teste')\n",
        "except Exception as e:\n",
        "  print(f'Folders not found')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ub35Vb3Q0uxK",
        "outputId": "d1d4e19e-53d1-4d14-99b6-e06436c9686f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folders not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip dataset\n",
        "!unzip /content/drive/MyDrive/Colab\\ Notebooks/Cap9/EuroSAT_RGB.zip"
      ],
      "metadata": {
        "id": "MdS9NPrA1VQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isdir('train_images'):\n",
        "  os.mkdir('train_images')\n",
        "if not os.path.isdir('test_images'):\n",
        "  os.mkdir('test_images')"
      ],
      "metadata": {
        "id": "XeUSzHfx2FNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_images = 'EuroSAT_RGB'\n",
        "destination_train = 'train_images'\n",
        "destination_test = 'test_images'"
      ],
      "metadata": {
        "id": "E8zUJRgr2xId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Separating Images**"
      ],
      "metadata": {
        "id": "nHFP2Wekf-F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_class = 0\n",
        "class_dict = {}"
      ],
      "metadata": {
        "id": "Ht5KBI44gDA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir(source_images)\n",
        "files.sort()"
      ],
      "metadata": {
        "id": "h-y0ARgdgere"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over all images\n",
        "for file_path in files:\n",
        "  # Check if the file is not a hidden file\n",
        "  if file_path[0] != '.':\n",
        "    # List all images in the current directory\n",
        "    images = os.listdir(source_images + '/' + file_path)\n",
        "\n",
        "    # Calculate sample size for training (80% of images)\n",
        "    sample_size = int(len(images) * 0.8)\n",
        "\n",
        "    # Initialize a list to store training image names\n",
        "    train = []\n",
        "\n",
        "    # Define the destination path for training images\n",
        "    final_dest = destination_train + '/' + str(image_class)\n",
        "\n",
        "    # Create the destination directory for training images\n",
        "    os.mkdir(final_dest)\n",
        "\n",
        "    # Copy a random sample of images to the training directory\n",
        "    for file_name in random.sample(images, sample_size):\n",
        "      shutil.copy2(os.path.join(source_images, file_path, file_name), final_dest)\n",
        "\n",
        "      # Add the file name to the training list\n",
        "      train.append(file_name)\n",
        "\n",
        "    # Determine the test images by subtracting the training images from all images\n",
        "    test_images = list(set(images) - set(train))\n",
        "\n",
        "    # Define the destination path for test images\n",
        "    final_dest = destination_test + '/' + str(image_class)\n",
        "\n",
        "    # Create the destination directory for test images\n",
        "    os.mkdir(final_dest)\n",
        "\n",
        "    # Copy the test images to the test directory\n",
        "    for test_image in test_images:\n",
        "      shutil.copy2(os.path.join(source_images, file_path, test_image), final_dest)\n",
        "\n",
        "    # Map the current class index to the file path in the class dictionary\n",
        "    class_dict[image_class] = file_path\n",
        "\n",
        "    # Increment the class index for the next iteration\n",
        "    image_class += 1"
      ],
      "metadata": {
        "id": "pOQpbJEkhl4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PreProcessing and Creating DataLoader**"
      ],
      "metadata": {
        "id": "yXodnYTPp0Td"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Transformation\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")"
      ],
      "metadata": {
        "id": "aROyt6Ydp8U0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torchvision.datasets.ImageFolder(root = 'train_images', transform = transform)\n",
        "\n",
        "dl_train = torch.utils.data.DataLoader(train_dataset, batch_size = 64, shuffle = True, num_workers = 2)"
      ],
      "metadata": {
        "id": "74DEFJ5RqqVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = torchvision.datasets.ImageFolder(root = 'test_images', transform = transform)\n",
        "\n",
        "dl_test = torch.utils.data.DataLoader(test_dataset, batch_size = 1, shuffle = True, num_workers = 2)"
      ],
      "metadata": {
        "id": "RDziOO9ZrJDZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Plotting Images**"
      ],
      "metadata": {
        "id": "dRk-9lijtgp4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(img):\n",
        "  img = img / 2 + 0.5\n",
        "\n",
        "  npimg = img.numpy()\n",
        "\n",
        "  plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "0Cm2otH4trCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataiter = iter(dl_train)\n",
        "images, labels = next(dataiter)"
      ],
      "metadata": {
        "id": "_bPxFVW9uA23"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapping = {0: 'AnnualCrop',\n",
        "           1: 'Forest',\n",
        "           2: 'HerbaceousVegetation',\n",
        "           3: 'Highway',\n",
        "           4: 'Industrial',\n",
        "           5: 'Pasture',\n",
        "           6: 'PermanentCrop',\n",
        "           7: 'Residential',\n",
        "           8: 'River',\n",
        "           9: 'SeaLake'}"
      ],
      "metadata": {
        "id": "mZ29Jz4UuGZf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imshow(torchvision.utils.make_grid(images[:8]))\n",
        "print('Labels:', ' '.join('%d' % labels[j] for j in range(8)))"
      ],
      "metadata": {
        "id": "cwpblpVXu0sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Creating Model**"
      ],
      "metadata": {
        "id": "WePbafhU7mMs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a convolutional neural network (ConvNet) class\n",
        "class ConvNet(nn.Module):\n",
        "  # Initialization method for the class\n",
        "  def __init__(self):\n",
        "    # Call the initialization method of the parent class (nn.Module)\n",
        "    super(ConvNet, self).__init__()\n",
        "\n",
        "    # Define the first convolutional layer\n",
        "    # This layer takes images with 3 channels (RGB), produces 64 feature maps,\n",
        "    # uses filters of size 3x3, and a stride of 1\n",
        "    self.conv1 = nn.Conv2d(3, 64, 3, 1)\n",
        "\n",
        "    # Define the second convolutional layer\n",
        "    # This layer takes the 64 feature maps from the previous layer and produces 128 new maps,\n",
        "    # with filters of size 3x3 and a stride of 1\n",
        "    self.conv2 = nn.Conv2d(64, 128, 3, 1)\n",
        "\n",
        "    # Define the third convolutional layer\n",
        "    # This layer takes the 128 feature maps from the previous layer and produces 256 new maps,\n",
        "    # with filters of size 3x3 and a stride of 1\n",
        "    self.conv3 = nn.Conv2d(128, 256, 3, 1)\n",
        "\n",
        "    # Define a dropout layer with a rate of 25% for regularization\n",
        "    # This helps prevent overfitting during training\n",
        "    self.dropout1 = nn.Dropout(0.25)\n",
        "\n",
        "    # Define a second dropout layer with a rate of 50%\n",
        "    # Provides additional regularization in later layers\n",
        "    self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "    # Define the first fully connected layer\n",
        "    # This layer takes an input of size 215296 and outputs 2048 features\n",
        "    self.fc1 = nn.Linear(215296, 2048)\n",
        "\n",
        "    # Define the second fully connected layer\n",
        "    # This layer takes the 2048 features from the previous layer and outputs 512 features\n",
        "    self.fc2 = nn.Linear(2048, 512)\n",
        "\n",
        "    # Define the third fully connected layer\n",
        "    # This layer takes the 512 features from the previous layer and outputs 128 features\n",
        "    self.fc3 = nn.Linear(512, 128)\n",
        "\n",
        "    # Define the fourth fully connected layer\n",
        "    # This layer takes the 128 features from the previous layer and outputs 10 features\n",
        "    # Typically, this would correspond to the number of classes in a classification problem\n",
        "    self.fc4 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    # Apply the first convolutional layer\n",
        "    x = self.conv1(x)\n",
        "\n",
        "    # Apply ReLU activation function\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # Apply the second convolutional layer\n",
        "    x = self.conv2(x)\n",
        "\n",
        "    # Apply ReLU activation function\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # Apply the third convolutional layer\n",
        "    x = self.conv3(x)\n",
        "\n",
        "    # Apply ReLU activation function\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # Apply max pooling with a kernel size of 2\n",
        "    x = F.max_pool2d(x, 2)\n",
        "\n",
        "    # Apply the first dropout layer\n",
        "    x = self.dropout1(x)\n",
        "\n",
        "    # Flatten the tensor while keeping the batch size (dimension 0) intact\n",
        "    x = torch.flatten(x, 1)\n",
        "\n",
        "    # Apply the first fully connected layer\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    # Apply ReLU activation function\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # Apply the second dropout layer\n",
        "    x = self.dropout2(x)\n",
        "\n",
        "    # Apply the second fully connected layer\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    # Apply ReLU activation function\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # Apply the third fully connected layer\n",
        "    x = self.fc3(x)\n",
        "\n",
        "    # Apply ReLU activation function\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # Apply the fourth fully connected layer\n",
        "    x = self.fc4(x)\n",
        "\n",
        "    # Apply log softmax activation function for the output\n",
        "    return F.log_softmax(x, dim=1)\n"
      ],
      "metadata": {
        "id": "r6VSjQqR4dxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet()"
      ],
      "metadata": {
        "id": "zJnUv3Z_6Whl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "ltXyNV2C2VSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "id": "BwCYIdv-2fqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Selecting Loss Function**"
      ],
      "metadata": {
        "id": "kBwTJrSa2iEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "VxhXd5rC2llj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Selecting Optmizer Function**"
      ],
      "metadata": {
        "id": "JSrH9ZIg4xrY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "metadata": {
        "id": "D4GJwrDu41XJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training the Model**"
      ],
      "metadata": {
        "id": "I-KJ6txB_74r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30"
      ],
      "metadata": {
        "id": "grVe-PKx_6aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testiter = next(dl_test)"
      ],
      "metadata": {
        "id": "2-UiYJ6PAD1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "print('Training Started')\n",
        "\n",
        "# Loop through each epoch\n",
        "for epoch in range(epochs):\n",
        "  # Initialize the running loss for the epoch\n",
        "  running_loss = 0.0\n",
        "\n",
        "  i = 0\n",
        "\n",
        "  # Loop through the training data\n",
        "  for data in (pbar := tqdm(dl_train)):\n",
        "    # Update the progress bar description with the current epoch\n",
        "    pbar.set_description(f'\\nEpoch: {epoch}')\n",
        "\n",
        "    inputs, labels = data\n",
        "\n",
        "    # Move the inputs and labels to the specified device (e.g., GPU)\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "    # Zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Forward pass: compute the model output for the inputs\n",
        "    outputs = model(inputs)\n",
        "\n",
        "    # Compute the loss\n",
        "    loss = loss_function(outputs, labels)\n",
        "\n",
        "    # Backward pass: compute the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # Update the model parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # Accumulate the loss\n",
        "    running_loss += loss.item()\n",
        "\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    # Perform validation/testing every 100 iterations\n",
        "    if i % 100 == 0:\n",
        "      # Disable gradient calculation for validation/testing\n",
        "      with torch.no_grad():\n",
        "        # Get a batch of test images and labels\n",
        "        test_images, test_labels = next(testiter)\n",
        "        test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
        "\n",
        "        test_outputs = model(test_images)\n",
        "\n",
        "        # Get the predicted class labels\n",
        "        _, predicted = torch.max(test_outputs, 1)\n",
        "\n",
        "    i += 1\n",
        "\n",
        "    print(f'Epoch: {epoch}, Loss: {running_loss / (i)}')\n",
        "\n",
        "print('Training Completed')\n"
      ],
      "metadata": {
        "id": "RWqN5x-NAG-I"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}